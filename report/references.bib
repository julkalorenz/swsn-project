@misc{zhou2024correctingmisinformationsocialmedia,
      title={Correcting misinformation on social media with a large language model}, 
      author={Xinyi Zhou and Ashish Sharma and Amy X. Zhang and Tim Althoff},
      year={2024},
      eprint={2403.11169},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2403.11169}, 
}

// dataset 2 fake news
@article{shu2017fake, title={Fake News Detection on Social Media: A Data Mining Perspective}, author={Shu, Kai and Sliva, Amy and Wang, Suhang and Tang, Jiliang and Liu, Huan}, journal={ACM SIGKDD Explorations Newsletter}, volume={19}, number={1}, pages={22--36}, year={2017}, publisher={ACM} }

@article{shu2017exploiting, title={Exploiting Tri-Relationship for Fake News Detection}, author={Shu, Kai and Wang, Suhang and Liu, Huan}, journal={arXiv preprint arXiv:1712.07709}, year={2017} }

@article{shu2018fakenewsnet, title={FakeNewsNet: A Data Repository with News Content, Social Context and Dynamic Information for Studying Fake News on Social Media}, author={Shu, Kai and Mahudeswaran, Deepak and Wang, Suhang and Lee, Dongwon and Liu, Huan}, journal={arXiv preprint arXiv:1809.01286}, year={2018} }

@article{doi:10.1177/17456916221141344,
      author = {Zoë Adams and Magda Osman and Christos Bechlivanidis and Björn Meder},
      title ={(Why) Is Misinformation a Problem?},
      journal = {Perspectives on Psychological Science},
      volume = {18},
      number = {6},
      pages = {1436-1463},
      year = {2023},
      doi = {10.1177/17456916221141344},
      note ={PMID: 36795592},
      URL = {https://doi.org/10.1177/17456916221141344},
      eprint = { https://doi.org/10.1177/17456916221141344}
      }

@article{KHAN2021100032,
      title = {A benchmark study of machine learning models for online fake news detection},
      journal = {Machine Learning with Applications},
      volume = {4},
      pages = {100032},
      year = {2021},
      issn = {2666-8270},
      doi = {https://doi.org/10.1016/j.mlwa.2021.100032},
      url = {https://www.sciencedirect.com/science/article/pii/S266682702100013X},
      author = {Junaed Younus Khan and Md. Tawkat Islam Khondaker and Sadia Afroz and Gias Uddin and Anindya Iqbal},
      keywords = {Fake news, Fake news detection, Benchmark study, Machine learning, Neural network, Deep learning, BERT, Natural language processing},
      abstract = {The proliferation of fake news and its propagation on social media has become a major concern due to its ability to create devastating impacts. Different machine learning approaches have been suggested to detect fake news. However, most of those focused on a specific type of news (such as political) which leads us to the question of dataset-bias of the models used. In this research, we conducted a benchmark study to assess the performance of different applicable machine learning approaches on three different datasets where we accumulated the largest and most diversified one. We explored a number of advanced pre-trained language models for fake news detection along with the traditional and deep learning ones and compared their performances from different aspects for the first time to the best of our knowledge. We find that BERT and similar pre-trained models perform the best for fake news detection, especially with very small dataset. Hence, these models are significantly better option for languages with limited electronic contents, i.e., training data. We also carried out several analysis based on the models’ performance, article’s topic, article’s length, and discussed different lessons learned from them. We believe that this benchmark study will help the research community to explore further and news sites/blogs to select the most appropriate fake news detection method.}
}

@article{10.1162/tacl_a_00454,
    author = {Guo, Zhijiang and Schlichtkrull, Michael and Vlachos, Andreas},
    title = {A Survey on Automated Fact-Checking},
    journal = {Transactions of the Association for Computational Linguistics},
    volume = {10},
    pages = {178-206},
    year = {2022},
    month = {02},
    abstract = {Fact-checking has become increasingly important due to the speed with which both
                    information and misinformation can spread in the modern media ecosystem.
                    Therefore, researchers have been exploring how fact-checking can be automated,
                    using techniques based on natural language processing, machine learning,
                    knowledge representation, and databases to automatically predict the veracity of
                    claims. In this paper, we survey automated fact-checking stemming from natural
                    language processing, and discuss its connections to related tasks and
                    disciplines. In this process, we present an overview of existing datasets and
                    models, aiming to unify the various definitions given and identify common
                    concepts. Finally, we highlight challenges for future research.},
    issn = {2307-387X},
    doi = {10.1162/tacl_a_00454},
    url = {https://doi.org/10.1162/tacl_a_00454},
    eprint = {https://direct.mit.edu/tacl/article-pdf/doi/10.1162/tacl_a_00454/1987018/tacl_a_00454.pdf},
}



